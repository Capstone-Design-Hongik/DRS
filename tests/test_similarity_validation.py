"""
DRS ìœ ì‚¬ë„ ê²€ì¦ í…ŒìŠ¤íŠ¸

êµìˆ˜ë‹˜ ì¶”ì²œ: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ ê°ê´€ì  ê²€ì¦

í…ŒìŠ¤íŠ¸ ì „ëµ:
1. Ground Truth ë°ì´í„°ì…‹ ìƒì„±
2. ì •ëŸ‰ì  í‰ê°€ ì§€í‘œ ê³„ì‚°
3. ìë™í™”ëœ ê²€ì¦
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import pandas as pd
from typing import List, Tuple, Dict
import json
from datetime import datetime

from app.features import normalize_pipeline
from app.similar import rank_top_k, ensemble_score
from app.data_io import load_ma20_parquet


class SimilarityValidator:
    """ìœ ì‚¬ë„ ê²€ì¦ í´ë˜ìŠ¤"""

    def __init__(self):
        self.test_cases = []
        self.results = []

    def create_test_pattern(self, pattern_type: str, length: int = 200) -> np.ndarray:
        """
        í…ŒìŠ¤íŠ¸ íŒ¨í„´ ìƒì„±

        Args:
            pattern_type: íŒ¨í„´ ìœ í˜•
                - "uptrend": ìƒìŠ¹ ì¶”ì„¸
                - "downtrend": í•˜ë½ ì¶”ì„¸
                - "peak": ì‚° ëª¨ì–‘ (ì˜¬ë¼ê°”ë‹¤ ë‚´ë ¤ì˜´)
                - "valley": ê³¨ì§œê¸° (ë‚´ë ¤ê°”ë‹¤ ì˜¬ë¼ì˜´)
                - "sine": ì‚¬ì¸íŒŒ (ì£¼ê¸°ì  ë³€ë™)
                - "flat": í‰í‰í•¨ (ë³€ë™ ì—†ìŒ)
            length: íŒ¨í„´ ê¸¸ì´

        Returns:
            ì •ê·œí™”ëœ íŒ¨í„´ (length ê¸¸ì´)
        """
        x = np.linspace(0, 1, length)

        if pattern_type == "uptrend":
            y = x  # 0 â†’ 1 ì„ í˜• ì¦ê°€

        elif pattern_type == "downtrend":
            y = 1 - x  # 1 â†’ 0 ì„ í˜• ê°ì†Œ

        elif pattern_type == "peak":
            # 0 â†’ 1 â†’ 0 (ì‚° ëª¨ì–‘)
            y = np.where(x < 0.5, 2 * x, 2 * (1 - x))

        elif pattern_type == "valley":
            # 1 â†’ 0 â†’ 1 (ê³¨ì§œê¸°)
            y = np.where(x < 0.5, 1 - 2 * x, 2 * x - 1)

        elif pattern_type == "sine":
            # ì‚¬ì¸íŒŒ (2ì£¼ê¸°)
            y = 0.5 + 0.5 * np.sin(4 * np.pi * x)

        elif pattern_type == "flat":
            # í‰í‰í•¨
            y = np.ones(length) * 0.5

        else:
            raise ValueError(f"Unknown pattern type: {pattern_type}")

        # Z-score ì •ê·œí™”
        return normalize_pipeline(y, length)

    def add_noise(self, pattern: np.ndarray, noise_level: float = 0.1) -> np.ndarray:
        """íŒ¨í„´ì— ë…¸ì´ì¦ˆ ì¶”ê°€"""
        noise = np.random.normal(0, noise_level, len(pattern))
        return pattern + noise

    def generate_test_dataset(self) -> List[Dict]:
        """
        í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±

        ê° íŒ¨í„´ì— ëŒ€í•´:
        1. ì›ë³¸ íŒ¨í„´
        2. ë…¸ì´ì¦ˆ ì¶”ê°€ íŒ¨í„´ (ë‚®ìŒ)
        3. ë…¸ì´ì¦ˆ ì¶”ê°€ íŒ¨í„´ (ë†’ìŒ)
        4. ë°˜ëŒ€ íŒ¨í„´
        """
        patterns = ["uptrend", "downtrend", "peak", "valley", "sine"]
        dataset = []

        for pattern_type in patterns:
            # ì›ë³¸ íŒ¨í„´
            original = self.create_test_pattern(pattern_type)

            # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: ìê¸° ìì‹  (100% ìœ ì‚¬)
            dataset.append({
                "query_name": f"{pattern_type}_original",
                "query_pattern": original.tolist(),
                "expected_similar": [f"{pattern_type}_original"],
                "expected_score_range": (0.9, 1.0),
                "description": "ë™ì¼ íŒ¨í„´ ê²€ìƒ‰ (ìê¸° ìì‹ )"
            })

            # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 2: ë‚®ì€ ë…¸ì´ì¦ˆ (80%+ ìœ ì‚¬)
            noisy_low = self.add_noise(original, noise_level=0.1)
            dataset.append({
                "query_name": f"{pattern_type}_noisy_low",
                "query_pattern": noisy_low.tolist(),
                "expected_similar": [f"{pattern_type}_original", f"{pattern_type}_noisy_low"],
                "expected_score_range": (0.7, 0.9),
                "description": "ë‚®ì€ ë…¸ì´ì¦ˆ ì¶”ê°€ (ë§¤ìš° ìœ ì‚¬)"
            })

            # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 3: ë†’ì€ ë…¸ì´ì¦ˆ (50%+ ìœ ì‚¬)
            noisy_high = self.add_noise(original, noise_level=0.3)
            dataset.append({
                "query_name": f"{pattern_type}_noisy_high",
                "query_pattern": noisy_high.tolist(),
                "expected_similar": [f"{pattern_type}_original"],
                "expected_score_range": (0.4, 0.7),
                "description": "ë†’ì€ ë…¸ì´ì¦ˆ ì¶”ê°€ (ìœ ì‚¬)"
            })

        # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 4: ë°˜ëŒ€ íŒ¨í„´ (ë‚®ì€ ìœ ì‚¬ë„)
        uptrend = self.create_test_pattern("uptrend")
        downtrend = self.create_test_pattern("downtrend")
        dataset.append({
            "query_name": "uptrend_vs_downtrend",
            "query_pattern": uptrend.tolist(),
            "expected_dissimilar": ["downtrend_original"],
            "expected_score_range": (0.0, 0.4),
            "description": "ë°˜ëŒ€ íŒ¨í„´ ê²€ìƒ‰ (ë¹„ìœ ì‚¬)"
        })

        return dataset

    def evaluate_precision_at_k(self, retrieved: List[str], relevant: List[str], k: int = 5) -> float:
        """
        Precision@K ê³„ì‚°

        ìƒìœ„ Kê°œ ê²°ê³¼ ì¤‘ ì •ë‹µì´ ëª‡ ê°œì¸ê°€?

        Args:
            retrieved: ê²€ìƒ‰ ê²°ê³¼ (ìˆœì„œëŒ€ë¡œ)
            relevant: ì •ë‹µ ë¦¬ìŠ¤íŠ¸
            k: ìƒìœ„ Kê°œ

        Returns:
            Precision@K (0~1)
        """
        if k == 0 or len(retrieved) == 0:
            return 0.0

        top_k = retrieved[:k]
        num_relevant = sum(1 for item in top_k if item in relevant)
        return num_relevant / k

    def evaluate_recall_at_k(self, retrieved: List[str], relevant: List[str], k: int = 5) -> float:
        """
        Recall@K ê³„ì‚°

        ì „ì²´ ì •ë‹µ ì¤‘ ìƒìœ„ Kê°œì— ëª‡ ê°œê°€ í¬í•¨ë˜ì—ˆëŠ”ê°€?

        Args:
            retrieved: ê²€ìƒ‰ ê²°ê³¼
            relevant: ì •ë‹µ ë¦¬ìŠ¤íŠ¸
            k: ìƒìœ„ Kê°œ

        Returns:
            Recall@K (0~1)
        """
        if len(relevant) == 0:
            return 0.0

        top_k = retrieved[:k]
        num_relevant = sum(1 for item in top_k if item in relevant)
        return num_relevant / len(relevant)

    def evaluate_ndcg_at_k(self, retrieved: List[str], relevant: List[str], k: int = 5) -> float:
        """
        NDCG@K (Normalized Discounted Cumulative Gain) ê³„ì‚°

        ìˆœìœ„ë¥¼ ê³ ë ¤í•œ í‰ê°€ ì§€í‘œ (ìƒìœ„ì— ì •ë‹µì´ ë§ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)

        Args:
            retrieved: ê²€ìƒ‰ ê²°ê³¼
            relevant: ì •ë‹µ ë¦¬ìŠ¤íŠ¸
            k: ìƒìœ„ Kê°œ

        Returns:
            NDCG@K (0~1)
        """
        def dcg(relevances):
            """DCG ê³„ì‚°"""
            return sum(rel / np.log2(i + 2) for i, rel in enumerate(relevances))

        # ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ì˜ relevance
        actual_relevances = [1 if item in relevant else 0 for item in retrieved[:k]]

        # ì´ìƒì ì¸ ìˆœìœ„ (ëª¨ë“  ì •ë‹µì´ ìƒìœ„ì—)
        ideal_relevances = sorted([1] * min(len(relevant), k) + [0] * (k - len(relevant)), reverse=True)

        actual_dcg = dcg(actual_relevances)
        ideal_dcg = dcg(ideal_relevances)

        if ideal_dcg == 0:
            return 0.0

        return actual_dcg / ideal_dcg

    def run_validation_on_real_data(self, test_cases: List[Dict]) -> Dict:
        """
        ì‹¤ì œ ì£¼ê°€ ë°ì´í„°ë¡œ ê²€ì¦

        Args:
            test_cases: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ë¦¬ìŠ¤íŠ¸

        Returns:
            ê²€ì¦ ê²°ê³¼
        """
        # MA20 ë°ì´í„° ë¡œë“œ
        df = load_ma20_parquet()
        if df is None or df.empty:
            raise ValueError("MA20 ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € /ingestë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

        from app.features import dict_to_matrix

        ma20 = {c: df[c].dropna() for c in df.columns}
        matrix, tickers = dict_to_matrix(ma20, target_len=200)

        results = []

        for test_case in test_cases:
            query_pattern = np.array(test_case["query_pattern"])

            # Top 5 ê²€ìƒ‰
            top_results = rank_top_k(query_pattern, matrix, tickers, k=5)
            retrieved_tickers = [t for t, _ in top_results]
            retrieved_scores = [s for _, s in top_results]

            # í‰ê°€ (ì‹¤ì œ ë°ì´í„°ì—ì„œëŠ” expected_similarë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì ìˆ˜ë§Œ í™•ì¸)
            result = {
                "test_case": test_case["query_name"],
                "description": test_case["description"],
                "top_5_results": [
                    {"ticker": t, "score": float(s)}
                    for t, s in top_results
                ],
                "avg_score": float(np.mean(retrieved_scores)),
                "max_score": float(np.max(retrieved_scores)),
                "min_score": float(np.min(retrieved_scores)),
                "expected_range": test_case.get("expected_score_range", (0.0, 1.0)),
                "in_range": test_case.get("expected_score_range", (0.0, 1.0))[0] <= np.max(retrieved_scores) <= test_case.get("expected_score_range", (0.0, 1.0))[1]
            }

            results.append(result)

        # ì „ì²´ ìš”ì•½
        summary = {
            "total_tests": len(results),
            "passed_tests": sum(1 for r in results if r["in_range"]),
            "avg_max_score": np.mean([r["max_score"] for r in results]),
            "avg_avg_score": np.mean([r["avg_score"] for r in results]),
        }

        return {
            "summary": summary,
            "details": results,
            "timestamp": datetime.now().isoformat()
        }

    def save_results(self, results: Dict, filename: str = "validation_results.json"):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        output_dir = os.path.join(os.path.dirname(__file__), "results")
        os.makedirs(output_dir, exist_ok=True)

        filepath = os.path.join(output_dir, filename)
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        print(f"âœ… ê²°ê³¼ ì €ì¥ë¨: {filepath}")
        return filepath


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("  DRS ìœ ì‚¬ë„ ê²€ì¦ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    print()

    validator = SimilarityValidator()

    # 1. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±
    print("ğŸ“¦ 1ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±...")
    test_dataset = validator.generate_test_dataset()
    print(f"   ìƒì„±ëœ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {len(test_dataset)}ê°œ")
    print()

    # 2. ì‹¤ì œ ë°ì´í„°ë¡œ ê²€ì¦
    print("ğŸ” 2ë‹¨ê³„: ì‹¤ì œ ì£¼ê°€ ë°ì´í„°ë¡œ ê²€ì¦...")
    try:
        results = validator.run_validation_on_real_data(test_dataset)

        # 3. ê²°ê³¼ ì¶œë ¥
        print()
        print("=" * 60)
        print("ğŸ“Š ê²€ì¦ ê²°ê³¼")
        print("=" * 60)
        print(f"ì´ í…ŒìŠ¤íŠ¸: {results['summary']['total_tests']}ê°œ")
        print(f"í†µê³¼: {results['summary']['passed_tests']}ê°œ")
        print(f"í‰ê·  ìµœê³  ì ìˆ˜: {results['summary']['avg_max_score']:.4f}")
        print(f"í‰ê·  í‰ê·  ì ìˆ˜: {results['summary']['avg_avg_score']:.4f}")
        print()

        # ìƒì„¸ ê²°ê³¼
        print("ğŸ“‹ ìƒì„¸ ê²°ê³¼:")
        print()
        for i, detail in enumerate(results['details'], 1):
            status = "âœ… PASS" if detail['in_range'] else "âŒ FAIL"
            print(f"{i}. {detail['test_case']} {status}")
            print(f"   ì„¤ëª…: {detail['description']}")
            print(f"   ì˜ˆìƒ ë²”ìœ„: {detail['expected_range']}")
            print(f"   ì‹¤ì œ ìµœê³  ì ìˆ˜: {detail['max_score']:.4f}")
            print(f"   Top 3 ê²°ê³¼:")
            for j, res in enumerate(detail['top_5_results'][:3], 1):
                print(f"      {j}. {res['ticker']}: {res['score']:.4f}")
            print()

        # 4. ê²°ê³¼ ì €ì¥
        print("ğŸ’¾ 3ë‹¨ê³„: ê²°ê³¼ ì €ì¥...")
        filepath = validator.save_results(results)
        print()

        print("=" * 60)
        print("âœ… ê²€ì¦ ì™„ë£Œ!")
        print("=" * 60)

    except ValueError as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        print()
        print("í•´ê²° ë°©ë²•:")
        print("1. ì„œë²„ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”")
        print("2. /ingest ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•˜ì—¬ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”")
        print("   curl -X POST 'http://localhost:8080/ingest?max_tickers=200' -H 'Content-Type: application/json' -d '{\"days\": 365}'")


if __name__ == "__main__":
    main()
